# -*- coding: utf-8 -*-
"""BitcoinPricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DPZhMqPtgr2DrkCz3iPnzCo9S06K6FAv
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
import matplotlib.pyplot as plt
from keras.callbacks import EarlyStopping
from tensorflow import keras
from tensorflow.random import set_seed
import json

from google.colab import drive
drive.mount('/content/drive')
set_seed(42)

#reads the historical prices dataset and assigns it to a dataframe
try:
    price_df = pd.read_csv('/content/drive/MyDrive/FYP Files/coinbaseDataset.csv', usecols=['Date', 'Close'], encoding='utf-8')
    price_df.replace(".", np.nan, inplace=True)
    price_df.dropna(inplace=True)
    if len(price_df) < 2:
        raise ValueError('Dataset must contain at least 2 rows')
    
except Exception as e:
    print(f"Error while reading HistoricalPrices.csv: {e}")
    raise

#reads the tweets sentiment dataset and assigns it to a dataframe
try:
    sentiment_df = pd.read_csv('/content/drive/MyDrive/FYP Files/TwitterSentiments.csv', usecols=['Date', 'Sentiment'], encoding='utf-8')
    sentiment_df.replace(".", np.nan, inplace=True)
    sentiment_df.dropna(inplace=True)
    if len(sentiment_df) < 2:
        raise ValueError('Dataset must contain at least 2 rows')
except Exception as e:
    print(f"Error while reading Sentiments.csv: {e}")
    raise

price_df['Date'] = pd.to_datetime(price_df['Date'])
sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])
merged_df = pd.merge(price_df, sentiment_df, on='Date')
merged_df['Date'] = pd.to_datetime(merged_df['Date'])

# This code is dividing a DataFrame merged_df into three subsets
train_size = int(len(merged_df) * 0.8)
val_df = merged_df[train_size:int(len(merged_df) * 0.9)]
train_df = merged_df[:train_size]
test_df = merged_df[train_size:]

# Prepare the data for the LSTM model/Normalization
scaler = MinMaxScaler()
train_df['normalized_price'] = scaler.fit_transform(train_df[['Close']])
test_df['normalized_price'] = scaler.transform(test_df[['Close']])
val_df['normalized_price'] = scaler.transform(val_df[['Close']])
train_df['positive_sentiment'] = (train_df['Sentiment'] == 1).astype(int)
train_df['negative_sentiment'] = (train_df['Sentiment'] == 0).astype(int)
test_df['positive_sentiment'] = (test_df['Sentiment'] == 1).astype(int)
test_df['negative_sentiment'] = (test_df['Sentiment'] == 0).astype(int)
val_df['positive_sentiment'] = (val_df['Sentiment'] == 1).astype(int)
val_df['negative_sentiment'] = (val_df['Sentiment'] == 0).astype(int)

# Define a function to create input sequences for LSTM model
def create_input_sequences(df, window_size):
    # Initialize empty lists to store input/output pairs
    X = []
    y = []
    # Loop over the DataFrame up to the second to last window of size window_size
    for i in range(len(df) - window_size):
        # Get the current window of size window_size
        window = df.iloc[i:(i + window_size)]
        # Extract the values of the columns we want as inputs (normalized_price, positive_sentiment, and negative_sentiment)
        # and append to the list of input sequences X
        X.append(window[['normalized_price', 'positive_sentiment', 'negative_sentiment']].values)
        # Get the value of the normalized_price column at the next time step (after the window)
        # and append to the list of output values y
        y.append(df.iloc[i + window_size]['normalized_price'])
    # Convert the lists to numpy arrays and return as a tuple (X, y)
    return np.array(X), np.array(y)

# Set the window size to 30
window_size = 30
# Create input/output pairs for the training, validation, and test DataFrames using the create_input_sequences function
X_train, y_train = create_input_sequences(train_df, window_size)
X_val, y_val = create_input_sequences(val_df, window_size)
X_test, y_test = create_input_sequences(test_df, window_size)

# Set up early stopping with a patience of 5 using the EarlyStopping callback from Keras
early_stop = EarlyStopping(monitor='val_loss', patience=5)

# Build and train the LSTM model
model = Sequential()
model.add(LSTM(64, activation='relu', input_shape=(window_size, 3)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, batch_size=32)
model.save("/content/drive/MyDrive/FYP Files/LSTM_Model.h5")

# Step 4: Make predictions
predicted_prices = []
for i in range(len(X_test)):
    input_data = X_test[i]
    predicted_price = model.predict(np.array([input_data]))[0][0]
    predicted_prices.append(predicted_price)
    
predicted_prices = scaler.inverse_transform(np.array(predicted_prices).reshape(-1, 1))

#convert the type of the test dataframe to a float for prediction purpose
test_df['Close'] = test_df['Close'].astype(float)
mse = np.mean(np.square(predicted_prices - test_df['Close'][window_size:].values))
print(f"Mean squared error: {mse}")
print(predicted_prices.dtype)
print(test_df['Close'].dtype)

# Predict next day's price
last_window = train_df.tail(window_size)[['normalized_price', 'positive_sentiment', 'negative_sentiment']].values
next_day_normalized_price = model.predict(np.array([last_window]))[0][0]
next_day_price = scaler.inverse_transform(np.array([[next_day_normalized_price]]))[0][0]
next_day = pd.date_range(merged_df['Date'].iloc[-1], periods=7, freq='D')
i = 1
print(f"Date: {next_day[i].strftime('%Y-%m-%d')}: Predicted price for next day: ${next_day_price}")

plt.plot(test_df['Close'][window_size:], label='Actual Price')
plt.plot(predicted_prices, label='Predicted Price')
plt.legend()
plt.show()

plt.figure(figsize=(8, 4))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

#Prints the prediction and saves the output in a txt file
print(f"Date: {next_day[i].strftime('%Y-%m-%d')}: Predicted price for next day: ${next_day_price}")
output_str = f"Date: {next_day[i].strftime('%Y-%m-%d')}, Price: ${next_day_price:.2f}"
print(output_str)

# Save the output to a text file
with open("output.txt", "w") as f:
    f.write(output_str)

plt.plot(predicted_prices, test_df['Close'][window_size:])
plt.show()

from sklearn.metrics import mean_squared_error

mean_squared_error(predicted_prices, test_df['Close'][window_size:], squared=False)